{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9083fb6f-2ee5-4a20-97c6-e3f281b0f7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ir-datasets in c:\\python311\\lib\\site-packages (0.5.9)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in c:\\python311\\lib\\site-packages (from ir-datasets) (4.12.3)\n",
      "Requirement already satisfied: inscriptis>=2.2.0 in c:\\python311\\lib\\site-packages (from ir-datasets) (2.5.0)\n",
      "Requirement already satisfied: lxml>=4.5.2 in c:\\python311\\lib\\site-packages (from ir-datasets) (5.3.0)\n",
      "Requirement already satisfied: numpy>=1.18.1 in c:\\python311\\lib\\site-packages (from ir-datasets) (1.26.4)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\python311\\lib\\site-packages (from ir-datasets) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.22.0 in c:\\python311\\lib\\site-packages (from ir-datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.38.0 in c:\\python311\\lib\\site-packages (from ir-datasets) (4.66.4)\n",
      "Requirement already satisfied: trec-car-tools>=2.5.4 in c:\\python311\\lib\\site-packages (from ir-datasets) (2.6)\n",
      "Requirement already satisfied: lz4>=3.1.10 in c:\\python311\\lib\\site-packages (from ir-datasets) (4.3.3)\n",
      "Requirement already satisfied: warc3-wet>=0.2.3 in c:\\python311\\lib\\site-packages (from ir-datasets) (0.2.5)\n",
      "Requirement already satisfied: warc3-wet-clueweb09>=0.2.5 in c:\\python311\\lib\\site-packages (from ir-datasets) (0.2.5)\n",
      "Requirement already satisfied: zlib-state>=0.1.3 in c:\\python311\\lib\\site-packages (from ir-datasets) (0.1.9)\n",
      "Requirement already satisfied: ijson>=3.1.3 in c:\\python311\\lib\\site-packages (from ir-datasets) (3.3.0)\n",
      "Requirement already satisfied: unlzw3>=0.2.1 in c:\\python311\\lib\\site-packages (from ir-datasets) (0.2.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\python311\\lib\\site-packages (from beautifulsoup4>=4.4.1->ir-datasets) (2.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python311\\lib\\site-packages (from requests>=2.22.0->ir-datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python311\\lib\\site-packages (from requests>=2.22.0->ir-datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python311\\lib\\site-packages (from requests>=2.22.0->ir-datasets) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python311\\lib\\site-packages (from requests>=2.22.0->ir-datasets) (2024.7.4)\n",
      "Requirement already satisfied: colorama in c:\\python311\\lib\\site-packages (from tqdm>=4.38.0->ir-datasets) (0.4.6)\n",
      "Requirement already satisfied: cbor>=1.0.0 in c:\\python311\\lib\\site-packages (from trec-car-tools>=2.5.4->ir-datasets) (1.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rank-bm25 in c:\\python311\\lib\\site-packages (0.2.2)\n",
      "Requirement already satisfied: numpy in c:\\python311\\lib\\site-packages (from rank-bm25) (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\python311\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\python311\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\python311\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\python311\\lib\\site-packages (from nltk) (2024.5.15)\n",
      "Requirement already satisfied: tqdm in c:\\python311\\lib\\site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: colorama in c:\\python311\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\python311\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\python311\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\manasi\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python311\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\python311\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\manasi\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\python311\\lib\\site-packages (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install ir-datasets\n",
    "! pip install rank-bm25\n",
    "! pip install nltk\n",
    "! pip install pandas\n",
    "! pip install numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edb4360c-f9ce-40b0-a0ac-4dc3f4fbaeeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] If you have a local copy of https://raw.githubusercontent.com/hltcoe/HC4/main/resources/hc4/rus/ids.0.jsonl.gz, you can symlink it here to avoid downloading it again: C:\\Users\\OmkarKadam\\.ir_datasets\\downloads\\4763df966f6ea953c731ef2d572044e5\n",
      "[INFO] [starting] https://raw.githubusercontent.com/hltcoe/HC4/main/resources/hc4/rus/ids.0.jsonl.gz\n",
      "[INFO] [finished] https://raw.githubusercontent.com/hltcoe/HC4/main/resources/hc4/rus/ids.0.jsonl.gz: [00:06] [26.8MB] [4.04MB/s]\n",
      "[INFO] If you have a local copy of https://raw.githubusercontent.com/hltcoe/HC4/main/resources/hc4/rus/ids.1.jsonl.gz, you can symlink it here to avoid downloading it again: C:\\Users\\OmkarKadam\\.ir_datasets\\downloads\\c19fb0dd1aceb0f6fd02f92818fa55b7\n",
      "[INFO] [starting] https://raw.githubusercontent.com/hltcoe/HC4/main/resources/hc4/rus/ids.1.jsonl.gz\n",
      "[INFO] [finished] https://raw.githubusercontent.com/hltcoe/HC4/main/resources/hc4/rus/ids.1.jsonl.gz: [00:09] [26.8MB] [2.87MB/s]\n",
      "[INFO] If you have a local copy of https://raw.githubusercontent.com/hltcoe/HC4/main/resources/hc4/rus/ids.2.jsonl.gz, you can symlink it here to avoid downloading it again: C:\\Users\\OmkarKadam\\.ir_datasets\\downloads\\41d6db2ae68b8a4a1e2b371e4f5fe7a8\n",
      "[INFO] [starting] https://raw.githubusercontent.com/hltcoe/HC4/main/resources/hc4/rus/ids.2.jsonl.gz\n",
      "[INFO] [finished] https://raw.githubusercontent.com/hltcoe/HC4/main/resources/hc4/rus/ids.2.jsonl.gz: [00:05] [26.8MB] [4.82MB/s]\n",
      "[INFO] If you have a local copy of https://raw.githubusercontent.com/hltcoe/HC4/main/resources/hc4/rus/ids.3.jsonl.gz, you can symlink it here to avoid downloading it again: C:\\Users\\OmkarKadam\\.ir_datasets\\downloads\\e3d20167c9fdce77e633b3ea0421cb51\n",
      "[INFO] [starting] https://raw.githubusercontent.com/hltcoe/HC4/main/resources/hc4/rus/ids.3.jsonl.gz\n",
      "[INFO] [finished] https://raw.githubusercontent.com/hltcoe/HC4/main/resources/hc4/rus/ids.3.jsonl.gz: [00:05] [26.8MB] [4.91MB/s]\n",
      "[INFO] If you have a local copy of https://raw.githubusercontent.com/hltcoe/HC4/main/resources/hc4/rus/ids.4.jsonl.gz, you can symlink it here to avoid downloading it again: C:\\Users\\OmkarKadam\\.ir_datasets\\downloads\\54db61aec1a4585ce172c39111725be7\n",
      "[INFO] [starting] https://raw.githubusercontent.com/hltcoe/HC4/main/resources/hc4/rus/ids.4.jsonl.gz\n",
      "[INFO] [finished] https://raw.githubusercontent.com/hltcoe/HC4/main/resources/hc4/rus/ids.4.jsonl.gz: [00:04] [26.8MB] [5.38MB/s]\n",
      "[INFO] If you have a local copy of https://raw.githubusercontent.com/hltcoe/HC4/main/resources/hc4/rus/ids.5.jsonl.gz, you can symlink it here to avoid downloading it again: C:\\Users\\OmkarKadam\\.ir_datasets\\downloads\\ba8a7bace2df0be82f80f7ae84f736d5\n",
      "[INFO] [starting] https://raw.githubusercontent.com/hltcoe/HC4/main/resources/hc4/rus/ids.5.jsonl.gz\n",
      "[INFO] [finished] https://raw.githubusercontent.com/hltcoe/HC4/main/resources/hc4/rus/ids.5.jsonl.gz: [00:09] [26.8MB] [2.70MB/s]\n",
      "[INFO] If you have a local copy of https://raw.githubusercontent.com/hltcoe/HC4/main/resources/hc4/rus/ids.6.jsonl.gz, you can symlink it here to avoid downloading it again: C:\\Users\\OmkarKadam\\.ir_datasets\\downloads\\9ada14526d375e2c7aaf95be80f8a043\n",
      "[INFO] [starting] https://raw.githubusercontent.com/hltcoe/HC4/main/resources/hc4/rus/ids.6.jsonl.gz\n",
      "[INFO] [finished] https://raw.githubusercontent.com/hltcoe/HC4/main/resources/hc4/rus/ids.6.jsonl.gz: [00:05] [26.8MB] [4.95MB/s]\n",
      "[INFO] If you have a local copy of https://raw.githubusercontent.com/hltcoe/HC4/main/resources/hc4/rus/ids.7.jsonl.gz, you can symlink it here to avoid downloading it again: C:\\Users\\OmkarKadam\\.ir_datasets\\downloads\\8555423b846aaf097527017cf8eda94c\n",
      "[INFO] [starting] https://raw.githubusercontent.com/hltcoe/HC4/main/resources/hc4/rus/ids.7.jsonl.gz\n",
      "[INFO] [finished] https://raw.githubusercontent.com/hltcoe/HC4/main/resources/hc4/rus/ids.7.jsonl.gz: [00:09] [23.3MB] [2.40MB/s]\n",
      "[INFO] If you have a local copy of https://huggingface.co/datasets/neuclir/neuclir1/resolve/main/data/rus-00000-of-00001.jsonl.gz?download=true, you can symlink it here to avoid downloading it again: C:\\Users\\OmkarKadam\\.ir_datasets\\downloads\\3aabc798a3b5dd92d7c47db9521870b1\n",
      "[INFO] [starting] https://huggingface.co/datasets/neuclir/neuclir1/resolve/main/data/rus-00000-of-00001.jsonl.gz?download=true\n",
      "[INFO] [finished] https://huggingface.co/datasets/neuclir/neuclir1/resolve/main/data/rus-00000-of-00001.jsonl.gz?download=true: [17:19] [4.50GB] [4.33MB/s]\n",
      "[INFO] [starting] https://raw.githubusercontent.com/hltcoe/HC4/main/resources/hc4/dev.topics.v1-0.jsonl                                  \n",
      "[INFO] [finished] https://raw.githubusercontent.com/hltcoe/HC4/main/resources/hc4/dev.topics.v1-0.jsonl: [00:00] [83.3kB] [14.2MB/s]\n",
      "[INFO] [starting] https://raw.githubusercontent.com/hltcoe/HC4/main/resources/hc4/test.topics.v1-0.jsonl          \n",
      "[INFO] [finished] https://raw.githubusercontent.com/hltcoe/HC4/main/resources/hc4/test.topics.v1-0.jsonl: [00:00] [984kB] [7.14MB/s]\n",
      "[INFO] [starting] https://raw.githubusercontent.com/hltcoe/HC4/main/resources/hc4/rus/dev.qrels.v1-0.txt          \n",
      "[INFO] [finished] https://raw.githubusercontent.com/hltcoe/HC4/main/resources/hc4/rus/dev.qrels.v1-0.txt: [00:00] [11.5kB] [11.3MB/s]\n",
      "[INFO] [starting] https://raw.githubusercontent.com/hltcoe/HC4/main/resources/hc4/rus/test.qrels.v1-0.txt          \n",
      "[INFO] [finished] https://raw.githubusercontent.com/hltcoe/HC4/main/resources/hc4/rus/test.qrels.v1-0.txt: [00:00] [134kB] [1.93MB/s]\n",
      "                                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents columns: Index(['doc_id', 'title', 'text', 'url', 'time', 'cc_file'], dtype='object')\n",
      "Queries columns: Index(['query_id', 'title', 'description', 'ht_title', 'ht_description',\n",
      "       'mt_title', 'mt_description', 'narrative_by_relevance', 'report',\n",
      "       'report_url', 'report_date', 'translation_lang'],\n",
      "      dtype='object')\n",
      "Qrels columns: Index(['query_id', 'doc_id', 'relevance', 'iteration'], dtype='object')\n",
      "Final Documents columns: Index(['doc_id', 'title', 'text', 'url', 'time', 'cc_file'], dtype='object')\n",
      "Final Queries columns: Index(['query_id', 'text', 'description', 'ht_title', 'ht_description',\n",
      "       'mt_title', 'mt_description', 'narrative_by_relevance', 'report',\n",
      "       'report_url', 'report_date', 'translation_lang'],\n",
      "      dtype='object')\n",
      "Final Qrels columns: Index(['query_id', 'doc_id', 'relevance', 'iteration'], dtype='object')\n",
      "Final BM25 parameters:\n",
      "k1 = 1.3\n",
      "b = 0.6\n",
      "MAP = 0.008406819517930628\n",
      "MRR = 0.04012345679012346\n",
      "nDCG@10 = 0.007769456573977662\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies if needed (uncomment if running in a notebook environment):\n",
    "# !pip install ir-datasets\n",
    "# !pip install rank-bm25\n",
    "# !pip install nltk\n",
    "# !pip install pandas\n",
    "# !pip install numpy\n",
    "\n",
    "import ir_datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from rank_bm25 import BM25Okapi\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt', quiet=True)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Load datasets\n",
    "# -----------------------------------------------------\n",
    "def load_datasets():\n",
    "    datasets = {\n",
    "        \"ru\": ir_datasets.load(\"neuclir/1/ru/hc4-filtered\"),\n",
    "        \"zh\": ir_datasets.load(\"neuclir/1/zh/hc4-filtered\"),\n",
    "        \"fa\": ir_datasets.load(\"neuclir/1/fa/hc4-filtered\")\n",
    "    }\n",
    "    return datasets\n",
    "\n",
    "datasets = load_datasets()\n",
    "dataset = datasets[\"ru\"]\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Prepare documents and queries\n",
    "# -----------------------------------------------------\n",
    "docs_iter = list(dataset.docs_iter())\n",
    "queries_iter = list(dataset.queries_iter())\n",
    "qrels_iter = list(dataset.qrels_iter())\n",
    "\n",
    "documents = pd.DataFrame(docs_iter)\n",
    "queries = pd.DataFrame(queries_iter)\n",
    "qrels_df = pd.DataFrame(qrels_iter)\n",
    "\n",
    "print(\"Documents columns:\", documents.columns)\n",
    "print(\"Queries columns:\", queries.columns)\n",
    "print(\"Qrels columns:\", qrels_df.columns)\n",
    "\n",
    "# The code expects documents to have 'doc_id' and 'text'.\n",
    "if 'doc_id' not in documents.columns:\n",
    "    # Try to guess column name\n",
    "    # If there's a different column name for IDs, rename it.\n",
    "    # Example: if the dataset provides 'id' instead of 'doc_id'\n",
    "    if 'id' in documents.columns:\n",
    "        documents.rename(columns={'id':'doc_id'}, inplace=True)\n",
    "    else:\n",
    "        raise ValueError(\"Documents DataFrame missing 'doc_id' column and couldn't infer an alternative.\")\n",
    "\n",
    "if 'text' not in documents.columns:\n",
    "    # Try some common alternatives. For this dataset, it should be 'text'.\n",
    "    # If something else is present, rename accordingly.\n",
    "    # Example: if 'content' is available: documents.rename(columns={'content':'text'}, inplace=True)\n",
    "    # Just raise an error if not found.\n",
    "    raise ValueError(\"Documents DataFrame missing 'text' column. Please rename the appropriate column to 'text'.\")\n",
    "\n",
    "if 'query_id' not in queries.columns:\n",
    "    # Try to guess column name\n",
    "    # If there's 'id' column, rename it to 'query_id'.\n",
    "    if 'id' in queries.columns:\n",
    "        queries.rename(columns={'id':'query_id'}, inplace=True)\n",
    "    else:\n",
    "        raise ValueError(\"Queries DataFrame missing 'query_id' column and couldn't infer an alternative.\")\n",
    "\n",
    "if 'text' not in queries.columns:\n",
    "    # Use the 'title' column as the text if available\n",
    "    if 'title' in queries.columns:\n",
    "        queries.rename(columns={\"title\": \"text\"}, inplace=True)\n",
    "    else:\n",
    "        # If 'title' not available, try 'description'\n",
    "        if 'description' in queries.columns:\n",
    "            queries.rename(columns={\"description\": \"text\"}, inplace=True)\n",
    "        else:\n",
    "            raise ValueError(\"Queries DataFrame missing a suitable text column. No 'text', 'title', or 'description' found.\")\n",
    "\n",
    "if 'query_id' not in qrels_df.columns or 'doc_id' not in qrels_df.columns or 'relevance' not in qrels_df.columns:\n",
    "    raise ValueError(\"Qrels DataFrame missing required columns (query_id, doc_id, relevance).\")\n",
    "\n",
    "print(\"Final Documents columns:\", documents.columns)\n",
    "print(\"Final Queries columns:\", queries.columns)\n",
    "print(\"Final Qrels columns:\", qrels_df.columns)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Build dictionaries and tokenize\n",
    "# -----------------------------------------------------\n",
    "doc_texts = {row['doc_id']: row['text'] for _, row in documents.iterrows()}\n",
    "tokenized_docs = {d_id: word_tokenize(text.lower()) for d_id, text in doc_texts.items()}\n",
    "doc_ids = list(tokenized_docs.keys())\n",
    "doc_tokens_list = [tokenized_docs[d_id] for d_id in doc_ids]\n",
    "\n",
    "def build_bm25(k1, b):\n",
    "    return BM25Okapi(doc_tokens_list, k1=k1, b=b)\n",
    "\n",
    "def compute_metrics(bm25, top_k=10):\n",
    "    relevance_data = defaultdict(dict)\n",
    "    for _, row in qrels_df.iterrows():\n",
    "        qid, did, rel = row['query_id'], row['doc_id'], row['relevance']\n",
    "        relevance_data[qid][did] = rel\n",
    "\n",
    "    APs = []\n",
    "    RR = []\n",
    "    nDCG_vals = []\n",
    "\n",
    "    for _, q_row in queries.iterrows():\n",
    "        qid = q_row['query_id']\n",
    "        q_text = q_row['text']\n",
    "        if qid not in relevance_data:\n",
    "            # No relevance judgments => skip\n",
    "            continue\n",
    "\n",
    "        q_tokens = word_tokenize(q_text.lower())\n",
    "        scores = bm25.get_scores(q_tokens)\n",
    "        ranked_indices = np.argsort(scores)[::-1]\n",
    "        top_indices = ranked_indices[:top_k]\n",
    "        retrieved_doc_ids = [doc_ids[i] for i in top_indices]\n",
    "\n",
    "        rel_docs = relevance_data[qid]\n",
    "        relevant_doc_ids = {d for d, r in rel_docs.items() if r > 0}\n",
    "        if len(relevant_doc_ids) == 0:\n",
    "            # no relevant docs for this query\n",
    "            continue\n",
    "\n",
    "        # AP\n",
    "        num_relevant_found = 0\n",
    "        precision_sum = 0.0\n",
    "        for rank, d_id in enumerate(retrieved_doc_ids, start=1):\n",
    "            if d_id in relevant_doc_ids:\n",
    "                num_relevant_found += 1\n",
    "                precision_sum += num_relevant_found / rank\n",
    "        AP = precision_sum / len(relevant_doc_ids)\n",
    "        APs.append(AP)\n",
    "\n",
    "        # RR\n",
    "        rr_val = 0.0\n",
    "        for rank, d_id in enumerate(retrieved_doc_ids, start=1):\n",
    "            if d_id in relevant_doc_ids:\n",
    "                rr_val = 1.0 / rank\n",
    "                break\n",
    "        RR.append(rr_val)\n",
    "\n",
    "        # nDCG@10\n",
    "        def dcg(rels):\n",
    "            return sum((2**r - 1)/np.log2(idx+2) for idx, r in enumerate(rels))\n",
    "\n",
    "        retrieved_rels = [rel_docs.get(d_id,0) for d_id in retrieved_doc_ids]\n",
    "        ideal_rels = sorted(rel_docs.values(), reverse=True)[:top_k]\n",
    "\n",
    "        DCG = dcg(retrieved_rels)\n",
    "        IDCG = dcg(ideal_rels) if ideal_rels else 0\n",
    "        nDCG = (DCG / IDCG) if IDCG > 0 else 0.0\n",
    "        nDCG_vals.append(nDCG)\n",
    "\n",
    "    mean_map = np.mean(APs) if APs else 0.0\n",
    "    mean_mrr = np.mean(RR) if RR else 0.0\n",
    "    mean_ndcg = np.mean(nDCG_vals) if nDCG_vals else 0.0\n",
    "\n",
    "    return mean_map, mean_mrr, mean_ndcg\n",
    "\n",
    "# Parameter Tuning\n",
    "k1 = 1.2\n",
    "b = 0.75\n",
    "iterations = 5\n",
    "learning_rate = 0.1\n",
    "\n",
    "for it in range(iterations):\n",
    "    bm25_model = build_bm25(k1, b)\n",
    "    base_map, base_mrr, base_ndcg = compute_metrics(bm25_model)\n",
    "\n",
    "    # Try k1 + lr\n",
    "    bm25_test = build_bm25(k1 + learning_rate, b)\n",
    "    test_map1, _, _ = compute_metrics(bm25_test)\n",
    "\n",
    "    # Try k1 - lr\n",
    "    bm25_test = build_bm25(k1 - learning_rate, b)\n",
    "    test_map2, _, _ = compute_metrics(bm25_test)\n",
    "\n",
    "    # Update k1\n",
    "    if test_map1 > base_map and test_map1 > test_map2:\n",
    "        k1 = k1 + learning_rate\n",
    "        base_map = test_map1\n",
    "    elif test_map2 > base_map:\n",
    "        k1 = k1 - learning_rate\n",
    "        base_map = test_map2\n",
    "\n",
    "    # Try b + lr\n",
    "    bm25_test = build_bm25(k1, b + learning_rate)\n",
    "    test_map3, _, _ = compute_metrics(bm25_test)\n",
    "\n",
    "    # Try b - lr\n",
    "    bm25_test = build_bm25(k1, b - learning_rate)\n",
    "    test_map4, _, _ = compute_metrics(bm25_test)\n",
    "\n",
    "    # Update b\n",
    "    if test_map3 > base_map and test_map3 > test_map4:\n",
    "        b = b + learning_rate\n",
    "        base_map = test_map3\n",
    "    elif test_map4 > base_map:\n",
    "        b = b - learning_rate\n",
    "        base_map = test_map4\n",
    "\n",
    "    # Decay learning rate\n",
    "    learning_rate *= 0.5\n",
    "\n",
    "# Final evaluation\n",
    "final_bm25 = build_bm25(k1, b)\n",
    "final_map, final_mrr, final_ndcg = compute_metrics(final_bm25)\n",
    "\n",
    "print(\"Final BM25 parameters:\")\n",
    "print(\"k1 =\", k1)\n",
    "print(\"b =\", b)\n",
    "print(\"MAP =\", final_map)\n",
    "print(\"MRR =\", final_mrr)\n",
    "print(\"nDCG@10 =\", final_ndcg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a337c29c-30dc-4e93-90eb-b2de21be25cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
