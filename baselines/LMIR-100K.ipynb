{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3af88ef8",
   "metadata": {},
   "source": [
    "# LMIR-100K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c79c421",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ir-measures\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import ir_measures\n",
    "from ir_measures import nDCG, P, Judged\n",
    "#import nltk\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('punkt_tab')  # If punkt_tab is explicitly needed\n",
    "#import ir_datasets\n",
    "\n",
    "#nltk.download('punkt_tab')  # If punkt_tab is explicitly needed\n",
    "from funcs import load_datasets, get_docs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95d4ae46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated Queries (Sample):\n",
      "  query_id                                original_title  \\\n",
      "0        3                    British royal news impacts   \n",
      "1        6          Gibraltar's Sovereignty After Brexit   \n",
      "2       13                US-South Korea Trade Agreement   \n",
      "3       14  North Korean Earthquakes and Nuclear Testing   \n",
      "4      101      Shipwrecks and Historical European Trade   \n",
      "\n",
      "                                    translated_title  \\\n",
      "0                    British Royal News воздействует   \n",
      "1                Суверенитет Гибралтара после Brexit   \n",
      "2            Торговое соглашение о США и Южном Корее   \n",
      "3  Землетрясения и ядерные испытания в Северной К...   \n",
      "4  Кораблекрушения и историческая европейская тор...   \n",
      "\n",
      "                                original_description  \\\n",
      "0  What political and economic impacts does news ...   \n",
      "1  How will Gibraltar's sovereignty be impacted b...   \n",
      "2  How will South Korea benefit from or be harmed...   \n",
      "3  Are earthquakes in North Korea being caused by...   \n",
      "4  What information about trade and shipping has ...   \n",
      "\n",
      "                              translated_description  \n",
      "0  Какие политические и экономические последствия...  \n",
      "1  Как будет повлиять на суверенитет Гибралтара в...  \n",
      "2  Как Южная Корея выиграет или пострадает от пер...  \n",
      "3  Были ли землетрясения в Северной Корее вызваны...  \n",
      "4  Какая информация о торговле и судоходстве была...  \n",
      "\n",
      "Sample Queries from Dataset:\n",
      "  query_id                                         title  \\\n",
      "0        3                    British royal news impacts   \n",
      "1        6          Gibraltar's Sovereignty After Brexit   \n",
      "2       13                US-South Korea Trade Agreement   \n",
      "3       14  North Korean Earthquakes and Nuclear Testing   \n",
      "4      101      Shipwrecks and Historical European Trade   \n",
      "\n",
      "                                         description  \\\n",
      "0  What political and economic impacts does news ...   \n",
      "1  How will Gibraltar's sovereignty be impacted b...   \n",
      "2  How will South Korea benefit from or be harmed...   \n",
      "3  Are earthquakes in North Korea being caused by...   \n",
      "4  What information about trade and shipping has ...   \n",
      "\n",
      "                                            ht_title  \\\n",
      "0            Влияние британских королевских новостей   \n",
      "1              Суверенитет Гибралтара после Брексита   \n",
      "2              США-Южнокорейское торговое соглашение   \n",
      "3  Северокорейские землетрясения и ядерное испытание   \n",
      "4  Кораблекрушения и историческая Европейская тор...   \n",
      "\n",
      "                                      ht_description  \\\n",
      "0  Какое политическое и экономическое влияние нов...   \n",
      "1  Как на суверенитет Гибралтара повлияет на пере...   \n",
      "2  Как Южная Корея выиграет или пострадает от пер...   \n",
      "3  Являются ли землетрясения в Северной Корее сле...   \n",
      "4  Какая информация о торговле и судоходстве была...   \n",
      "\n",
      "                                            mt_title  \\\n",
      "0              Британские королевские новости влияют   \n",
      "1              Суверенитет Гибралтара после Брексита   \n",
      "2       Торговое соглашение между США и Южной Кореей   \n",
      "3  Северокорейские землетрясения и ядерные испытания   \n",
      "4  Кораблекрушения и историческая европейская тор...   \n",
      "\n",
      "                                      mt_description  \\\n",
      "0  Какие политические и экономические последствия...   \n",
      "1  Как повлияют на суверенитет Гибралтара перегов...   \n",
      "2  Каким образом Южная Корея извлечет выгоду из с...   \n",
      "3  Являются ли землетрясения в Северной Корее при...   \n",
      "4  Какая информация о торговле и судоходстве была...   \n",
      "\n",
      "                              narrative_by_relevance  \\\n",
      "0  {'very_valuable': 'Information regarding econo...   \n",
      "1  {'very_valuable': 'Gibraltar will remain a ter...   \n",
      "2  {'very_valuable': 'N/A', 'somewhat_valuable': ...   \n",
      "3  {'very_valuable': 'N/A', 'somewhat_valuable': ...   \n",
      "4  {'very_valuable': 'Shipwrecks that belonged to...   \n",
      "\n",
      "                                              report  \\\n",
      "0  Announcement of engagement\\nPrincess Eugenie o...   \n",
      "1  Sovereignty\\nSee also: Disputed status of Gibr...   \n",
      "2  South Korea reactions\\n\\t\\nThis section is in ...   \n",
      "3  On 3 September, at 3:31 AM UTC, the United Sta...   \n",
      "4  Portuguese discoveries (Portuguese: Descobrime...   \n",
      "\n",
      "                                          report_url report_date  \\\n",
      "0  https://en.wikipedia.org/w/index.php?title=Wed...  2018-05-13   \n",
      "1  https://en.wikipedia.org/w/index.php?title=Eff...  2018-11-26   \n",
      "2  https://en.wikipedia.org/w/index.php?title=Uni...  2018-02-20   \n",
      "3  https://en.wikipedia.org/w/index.php?title=201...  2017-09-22   \n",
      "4  https://en.wikipedia.org/w/index.php?title=Por...  2018-05-16   \n",
      "\n",
      "  translation_lang  \n",
      "0               ru  \n",
      "1               ru  \n",
      "2               ru  \n",
      "3               ru  \n",
      "4               ru  \n"
     ]
    }
   ],
   "source": [
    "from googletrans import Translator\n",
    "import pandas as pd\n",
    "from ir_datasets import load\n",
    "\n",
    "# Initialize the translator\n",
    "translator = Translator()\n",
    "\n",
    "datasets = load_datasets([\"ru\", \"zh\", \"fa\"])\n",
    "\n",
    "documents = pd.DataFrame(datasets[\"ru\"].docs_iter())\n",
    "# Load the Qrels and Queries\n",
    "qrels = pd.DataFrame(datasets[\"ru\"].qrels_iter())  # ground truth\n",
    "queries = pd.DataFrame(datasets[\"ru\"].queries_iter())  # queries in eng\n",
    "\n",
    "\n",
    "# Step 2: Filter and Translate Queries\n",
    "common_query_ids = set(qrels[\"query_id\"]).intersection(queries[\"query_id\"])\n",
    "filtered_queries = queries[queries[\"query_id\"].isin(common_query_ids)]\n",
    "\n",
    "# Translate queries to Russian\n",
    "translated_queries = []\n",
    "for _, query in filtered_queries.iterrows():\n",
    "    translated_title = translator.translate(query[\"title\"], src=\"en\", dest=\"ru\").text if \"title\" in query else None\n",
    "    translated_description = translator.translate(query[\"description\"], src=\"en\", dest=\"ru\").text if \"description\" in query else None\n",
    "\n",
    "    translated_queries.append({\n",
    "        \"query_id\": query[\"query_id\"],\n",
    "        \"original_title\": query[\"title\"],\n",
    "        \"translated_title\": translated_title,\n",
    "        \"original_description\": query[\"description\"],\n",
    "        \"translated_description\": translated_description\n",
    "    })\n",
    "\n",
    "translated_queries_df = pd.DataFrame(translated_queries)\n",
    "\n",
    "# Save Translated Queries for Inspection\n",
    "translated_queries_df.to_excel(\"translated_queries.xlsx\", index=False)\n",
    "\n",
    "\n",
    "# Save to Excel for inspection\n",
    "output_file = \"translated_queries.xlsx\"\n",
    "translated_queries_df.to_excel(output_file, index=False)\n",
    "\n",
    "# Display a sample of the translated queries\n",
    "print(\"Translated Queries (Sample):\")\n",
    "print(translated_queries_df.head())\n",
    "\n",
    "# Additional: Check the structure of the queries for inspection\n",
    "print(\"\\nSample Queries from Dataset:\")\n",
    "print(queries.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "16a07230",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "mystem = Mystem()\n",
    "stop_words_ru = set(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c6fb9ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing functions\n",
    "def preprocess(text):\n",
    "    \"\"\"Preprocess English text: tokenize, lowercase, remove punctuation and stop words.\"\"\"\n",
    "    if not isinstance(text, str):  # Handle potential NaN or non-string cases\n",
    "        return \"\"\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word.lower() for word in tokens if word.isalpha()]  # Remove non-alphabetic tokens\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)  # Return processed text as a string\n",
    "\n",
    "def preprocess_ru(text):\n",
    "    \"\"\"Preprocess Russian text: tokenize, lowercase, remove punctuation and stop words.\"\"\"\n",
    "    if not isinstance(text, str):  # Handle potential NaN or non-string cases\n",
    "        return \"\"\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word.lower() for word in tokens if word.isalpha()]\n",
    "    stop_words = set(stopwords.words('russian'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e6fa18a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of the subset: 100000\n",
      "Number of common documents: 680\n",
      "Number of random documents: 99320\n",
      "Sample of subset documents:\n",
      "                                 doc_id  \\\n",
      "0  9fafedc0-9cd5-4b05-95a1-a4d7cd2787b5   \n",
      "1  4b19d161-3750-4099-9310-37790bdea21d   \n",
      "2  220a75bf-419c-4a87-8afe-1e6378405133   \n",
      "3  19ec91bc-a3fb-46b7-a4b2-dd78d3ca8bfd   \n",
      "4  3419c14b-7018-428e-9ecf-75b2d02a6931   \n",
      "\n",
      "                                               title  \\\n",
      "0  Чуркин: доклада по химическим атакам в Сирии н...   \n",
      "1  Из Москвы в Эмираты пытались вывезти 30 красно...   \n",
      "2  Генпрокуратура не выявила серьезных нарушений ...   \n",
      "3  МОК поможет российским паралимпийцам восстанов...   \n",
      "4  Демонстрации за отставку президента Кореи собр...   \n",
      "\n",
      "                                                text  \\\n",
      "0  ООН, 31 августа. /Корр. ТАСС Олег Зеленин/. Ин...   \n",
      "1  В аэропорту Домодедово таможенники изъяли 30 р...   \n",
      "2  МОСКВА, 20 сентября. /ТАСС/. Генеральная проку...   \n",
      "3  Международный паралимпийский комитет (МПК) 21 ...   \n",
      "4  Демонстрации за отставку президента Южной Коре...   \n",
      "\n",
      "                               url                 time  \\\n",
      "0  http://tass.ru/politika/3578071                 None   \n",
      "1   http://izvestia.ru/news/632378  2016-09-14T12:34:00   \n",
      "2  http://tass.ru/politika/3637594                 None   \n",
      "3   http://izvestia.ru/news/647907  2016-11-28T03:41:00   \n",
      "4   http://izvestia.ru/news/649340  2016-12-03T22:32:00   \n",
      "\n",
      "                                             cc_file  \n",
      "0  crawl-data/CC-NEWS/2016/08/CC-NEWS-20160830145...  \n",
      "1  crawl-data/CC-NEWS/2016/09/CC-NEWS-20160913145...  \n",
      "2  crawl-data/CC-NEWS/2016/09/CC-NEWS-20160920065...  \n",
      "3  crawl-data/CC-NEWS/2016/11/CC-NEWS-20161127132...  \n",
      "4  crawl-data/CC-NEWS/2016/12/CC-NEWS-20161203132...  \n"
     ]
    }
   ],
   "source": [
    "# Identify `doc_id` values in Qrels\n",
    "common_doc_ids = set(qrels[\"doc_id\"])\n",
    "\n",
    "# Filter documents that match `common_doc_ids`\n",
    "common_documents = documents[documents[\"doc_id\"].isin(common_doc_ids)]\n",
    "\n",
    "# Calculate the remaining documents needed to reach 100,000\n",
    "remaining_size = 100000 - len(common_documents)\n",
    "\n",
    "# Randomly sample additional documents\n",
    "random_documents = documents[~documents[\"doc_id\"].isin(common_doc_ids)].sample(\n",
    "    n=remaining_size, random_state=42\n",
    ")\n",
    "\n",
    "# Combine common documents and random documents into the final subset\n",
    "subset_documents = pd.concat([common_documents, random_documents], ignore_index=True)\n",
    "\n",
    "# Save the subset to a CSV file\n",
    "subset_documents_path = \"subset_100k_documents.csv\"\n",
    "subset_documents.to_csv(subset_documents_path, index=False)\n",
    "\n",
    "# Save the filtered Qrels\n",
    "filtered_qrels = qrels[qrels[\"doc_id\"].isin(common_doc_ids)]\n",
    "filtered_qrels_path = \"filtered_qrels.csv\"\n",
    "filtered_qrels.to_csv(filtered_qrels_path, index=False)\n",
    "\n",
    "# Save the filtered Queries\n",
    "filtered_queries_path = \"filtered_queries.csv\"\n",
    "filtered_queries.to_csv(filtered_queries_path, index=False)\n",
    "\n",
    "# Verify and display information\n",
    "print(f\"Total size of the subset: {len(subset_documents)}\")\n",
    "print(f\"Number of common documents: {len(common_documents)}\")\n",
    "print(f\"Number of random documents: {len(random_documents)}\")\n",
    "print(\"Sample of subset documents:\")\n",
    "print(subset_documents.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "50586de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Documents:\n",
      "['оон августа тасс олег информации содержащейся в докладе совместной миссии оон и организации по запрещению химического оружия озхо по расследованию химических атак в сирии недостаточно для того чтобы возложить ответственность за некоторые инциденты на дамаск и ввести против него санкции совета безопасности такое мнение высказал во вторник постоянный представитель рф при оон виталий чуркин по итогам закрытой встречи сб спецпроект сирийская рапсодия жизнь между миром и войной в работах фотокорреспондентов тасс откровенно говоря нет сказал дипломат отвечая на соответствующий вопрос журналистов конечно мы продолжим анализировать доклад но опять же есть два случая в которых они возложили вину на сирийскую сторону у нас же есть очень серьезные вопросы к этим выводам прим тасс по словам чуркина в прошлом эксперты озхо уже установили что хлор скорее всего применялся в ходе конфликта в сирии но при этом нет неопровержимых доказательств того что к этому причастны сирийские правительственные силы дипломат подчеркнул что некоторые положения доклада миссии оон и озхо сформулированы так что не дают полной уверенности в том что выводы полностью точны выводы о причастности дамаска как заявил постоянный представитель сирии при оон башар джаафари доклад лишен доказательств и основан на показаниях очевидцев предоставленных террористами выводы содержащие в докладе были полностью основаны на заявлениях очевидцев предложенных террористическими вооруженными группами поэтому эти выводы лишены физических доказательств будь то образцы или медицинские отчеты которые бы подтвердили что хлор применялся так что у нас нет никаких физических доказательств сказал он по его словам это говорит о том что выводы в докладе подготовленном совместной миссией оон и озхо не могут считаться подкрепленными истиной джаафари подчеркнул необходимость продолжения изучения инцидентов о которых говорится в докладе пока не будут получены твердые факты он подчеркнул что дамаск со своей стороны продолжит работу в этом направлении сирийское правительство подчеркивает что предпримет все усилия в рамках национальных правовых процедур чтобы разобраться в этом вопросе и установить истину не предположения а именно факты нам нужно узнать правду без политизации этих инцидентов или их манипуляции в политических целях отметил дипломат введение санкций ранее дипломаты великобритании и франции заявили что будут добиваться от совета безопасности введения санкций в отношении ответственных за применение химического оружия в сирии доклад с результатами расследования проведенного экспертами оон и озхо был передан в совет безопасности августа специалисты в течение нескольких месяцев изучали девять химических атак совершенных в годах в трех случаях они смогли сделать выводы об ответственных за применение отравляющих веществ по утверждению экспертов им удалось собрать достаточно информации которая позволяет возложить на сирийские правительственные силы ответственность за две химические атаки в провинции идлиб в апреле года и в марте года в третьем случае имевшем место в провинции алеппо августа года единственными кто располагал возможностями мотивами и средствами для применения были боевики запрещенной в рф террористической группировки исламское государство говорится в докладе копией которого располагает тасс при этом в документе отмечается что с декабря года оон и озхо получили информацию о более чем возможных химических атаках в из которых предположительно применялся хлор об исламском государстве исламское государство иг исламистская террористическая организация действующая на территории ирака и сирии создана октября года в результате слияния радикальных суннитских формирований костяк группировки формируют боевики сражавшиеся с американскими войсками в период их пребывания в ираке и с силами правительства башара асада в сирии иг признано террористической организацией в сша канаде великобритании австралии турции египте оаэ индии индонезии а также в россии с декабря года террористическая организация исламское государство досье инфографика исламское государство в ираке и сирии территории под контролем боевиков иностранные наемники в рядах террористической группировки и крупнейшие теракты иг в инфографике тасс', 'в аэропорту домодедово таможенники изъяли редких птиц семейства соколиных пернатых занесенных в красную книгу пытались вывезти в объединенные арабские эмираты изъятых птиц поместили в центр передержки животных в москве как сообщает агентство городских новостей назначена экспертиза по определению вида птиц известия ранее писали что в заповеднике хакасский при попытке отлова краснокнижных хищников были задержаны два жители ближнего востока в качестве приманки охотники использовали живых голубей оснащенных специальными петлями в россии казахстане и монголии популяция краснокнижных пернатых семейства соколиных постепенно сокращается по мнению ученых это связано с нелегальным отловом соколов для дальнейшей продажи в арабские страны где популярна соколиная охота читайте также браконьеры с ближнего востока охотятся на хакасских соколов', 'москва сентября генеральная прокуратура рф не выявила серьезных нарушений на прошедших выборах в госдуму об этом тасс сообщил официальный представитель надзорного ведомства александр куренной по предварительным данным генеральной прокуратуры россии в ходе избирательной кампании в госдуму седьмого созыва существенных нарушений допущено не было сказал он количество жалоб в прокуратуру в ходе выборов значительно ниже чем на выборах года сообщил также куренной количество поступивших в прокуратуру жалоб оказалось значительно ниже в сравнении с аналогичной избирательной кампанией года сказал он', 'международный паралимпийский комитет мпк ноября текущего года направил в паралимпийский комитет россии пкр критерии восстановления членства в своих рядах по мнению пкр требования международного паралимпийского комитета являются довольно размытыми и нуждаются в детальном обсуждении и уточнении как пишет газета известия список критериев составленный мпк сочли слишком жестким и в международном олимпийском комитете мок который возглавляет томас бах руководство организации собирается вмешаться в диалог между мпк и пкр для скорейшего решения главной проблемы восстановления членства паралимпийского комитета россии в международной системе и впоследствии допуска российских спортсменов к паралимпиаде года которая пройдет в южной корее в городе пхенчхан более подробно читайте в эксклюзивном материале газеты известия мок заступится за российских паралимпийцев', 'демонстрации за отставку президента южной кореи пак кын хе собрали млн человек об этом сообщили иностранные сми со ссылкой на организаторов акции по нашим подсчетам в общей сложности на улицы вышли млн человек недовольных режимом пак кын хе цитирует тасс заявление оппозиции сообщается что демонстранты вышли с лозунгами долой пак кын хе и импичмент манифестации прошли по все стране только в сеуле на улицы вышли млн человек полиция сообщает что во время акций протеста никаких инцидентов не было более того отмечается что это уже шестая акция с требованием отставки главы государства которая стала фигурантом коррупционного скандала в ее окружении читайте также президент южной кореи готова досрочно покинуть свой пост']\n",
      "\n",
      "Processed Queries:\n",
      "['какие политические экономические последствия имеют новости британской королевской семье внутри страны рубежом', 'повлияют суверенитет гибралтара переговоры брексите испанией великобританией', 'каким образом южная корея извлечет выгоду соглашения свободной торговле соединенными штатами пострадает', 'являются землетрясения северной корее причиной ядерных испытаний', 'информация торговле судоходстве обнаружена исследованием исторических кораблекрушений европейских судов']\n",
      "\n",
      "Total number of processed documents: 100000\n",
      "Total number of processed queries: 54\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Apply preprocessing to documents\n",
    "subset_documents[\"processed_text\"] = subset_documents[\"text\"].apply(preprocess)\n",
    "\n",
    "\n",
    "queries[\"processed_description\"] = queries[\"mt_description\"].apply(preprocess_ru)\n",
    "\n",
    "\n",
    "# Step 4: Save the preprocessed datasets\n",
    "subset_documents.to_csv(\"processed_documents.csv\", index=False)\n",
    "queries.to_csv(\"processed_queries.csv\", index=False)\n",
    "\n",
    "# Step 5: Verify the preprocessing\n",
    "print(\"Processed Documents:\")\n",
    "print(subset_documents[\"processed_text\"].tolist()[:5])\n",
    "\n",
    "print(\"\\nProcessed Queries:\")\n",
    "print(queries[\"processed_description\"].tolist()[:5])\n",
    "\n",
    "# Display basic information about the final processed datasets\n",
    "print(f\"\\nTotal number of processed documents: {len(subset_documents)}\")\n",
    "print(f\"Total number of processed queries: {len(queries)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "59ce69fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0: Top Documents: [(4241, np.float64(0.00017669312430692338)), (5310, np.float64(0.00018237086786596074)), (22040, np.float64(0.0001894480600955912)), (46945, np.float64(0.00018946564556109028)), (10337, np.float64(0.00018973562109284888)), (13293, np.float64(0.00019813548120349299)), (14665, np.float64(0.00019818124025034774)), (27579, np.float64(0.00019819057083472367)), (7076, np.float64(0.00019821574989502456)), (5495, np.float64(0.00019837290573746164))]\n",
      "Query 1: Top Documents: [(9536, np.float64(0.00021101105950546554)), (3319, np.float64(0.00021101475644047117)), (11912, np.float64(0.00021102122505399889)), (36461, np.float64(0.00021108030639552797)), (43260, np.float64(0.00021108583970896758)), (10779, np.float64(0.00021117332383254177)), (26396, np.float64(0.00021118619612773683)), (28785, np.float64(0.0002123958853991612)), (26471, np.float64(0.00023135087914144252)), (4237, np.float64(0.00023139583818480654))]\n",
      "Query 2: Top Documents: [(29027, np.float64(0.0001341619722803982)), (22305, np.float64(0.000154278772695599)), (37828, np.float64(0.0001542825205925176)), (32056, np.float64(0.00015428720484936872)), (37997, np.float64(0.00015430406252546196)), (5745, np.float64(0.00015432652568642162)), (5963, np.float64(0.00015433868668221116)), (39196, np.float64(0.00015462547140884483)), (46354, np.float64(0.00015464771120777957)), (17204, np.float64(0.0001551112281901976))]\n",
      "Query 0: Top Documents: [(4241, np.float64(0.00017669312430692338)), (5310, np.float64(0.00018237086786596074)), (22040, np.float64(0.0001894480600955912)), (46945, np.float64(0.00018946564556109028)), (10337, np.float64(0.00018973562109284888)), (13293, np.float64(0.00019813548120349299)), (14665, np.float64(0.00019818124025034774)), (27579, np.float64(0.00019819057083472367)), (7076, np.float64(0.00019821574989502456)), (5495, np.float64(0.00019837290573746164))]\n",
      "Query 1: Top Documents: [(9536, np.float64(0.00021101105950546554)), (3319, np.float64(0.00021101475644047117)), (11912, np.float64(0.00021102122505399889)), (36461, np.float64(0.00021108030639552797)), (43260, np.float64(0.00021108583970896758)), (10779, np.float64(0.00021117332383254177)), (26396, np.float64(0.00021118619612773683)), (28785, np.float64(0.0002123958853991612)), (26471, np.float64(0.00023135087914144252)), (4237, np.float64(0.00023139583818480654))]\n",
      "Query 2: Top Documents: [(29027, np.float64(0.0001341619722803982)), (22305, np.float64(0.000154278772695599)), (37828, np.float64(0.0001542825205925176)), (32056, np.float64(0.00015428720484936872)), (37997, np.float64(0.00015430406252546196)), (5745, np.float64(0.00015432652568642162)), (5963, np.float64(0.00015433868668221116)), (39196, np.float64(0.00015462547140884483)), (46354, np.float64(0.00015464771120777957)), (17204, np.float64(0.0001551112281901976))]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "vocabulary = set(word for doc in processed_documents for word in doc.split())\n",
    "\n",
    "alpha = 0.1  # Smoothing parameter, adjust as necessary\n",
    "\n",
    "def build_lm(tokens):\n",
    "    count = Counter(tokens)\n",
    "    total_tokens = sum(count.values()) or 1  # Avoid division by zero\n",
    "    # Only store non-zero probabilities\n",
    "    return {word: (count[word] + alpha) / (total_tokens + alpha * len(vocabulary)) for word in count}\n",
    "\n",
    "# Rebuild language models using the revised function\n",
    "doc_models = {idx: build_lm(doc.split()) for idx, doc in enumerate(processed_documents)}\n",
    "\n",
    "# Same for queries\n",
    "query_models = {idx: build_lm(query.split()) for idx, query in enumerate(processed_queries)}\n",
    "\n",
    "# Revised KL divergence calculation using sparse models\n",
    "def kl_divergence(lm_query, lm_document):\n",
    "    kl_div = 0\n",
    "    for word in lm_query:\n",
    "        prob_q = lm_query[word]\n",
    "        prob_d = lm_document.get(word, alpha / (alpha * len(vocabulary)))\n",
    "        kl_div += prob_q * np.log(prob_q / prob_d)\n",
    "    return kl_div\n",
    "\n",
    "# Calculate similarities with sparse models\n",
    "similarities = {q_id: {doc_id: kl_divergence(qm, dm) for doc_id, dm in doc_models.items()} for q_id, qm in query_models.items()}\n",
    "\n",
    "\n",
    "top_n = 10\n",
    "similar_documents = {\n",
    "    q_id: sorted(doc_sims.items(), key=lambda item: item[1])[:top_n] for q_id, doc_sims in similarities.items()\n",
    "}\n",
    "\n",
    "# Display results for the first three queries\n",
    "for q_id in sorted(similar_documents.keys())[:3]:\n",
    "    print(f\"Query {q_id}: Top Documents: {similar_documents[q_id]}\")\n",
    "\n",
    "# Collect results\n",
    "results = []\n",
    "for q_id, docs in similar_documents.items():\n",
    "    for doc_id, score in docs:\n",
    "        results.append({\"query_id\": q_id, \"doc_id\": doc_id, \"score\": score})\n",
    "\n",
    "# Display results for the first three queries\n",
    "for q_id in sorted(similar_documents.keys())[:3]:\n",
    "    print(f\"Query {q_id}: Top Documents: {similar_documents[q_id]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "93083cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   query_id  doc_id     score\n",
      "0         0    4241  0.000177\n",
      "1         0    5310  0.000182\n",
      "2         0   22040  0.000189\n",
      "3         0   46945  0.000189\n",
      "4         0   10337  0.000190\n"
     ]
    }
   ],
   "source": [
    "# Collect results in a list\n",
    "results = []\n",
    "for q_id, docs in similar_documents.items():\n",
    "    for doc_id, score in docs:\n",
    "        results.append({\"query_id\": q_id, \"doc_id\": doc_id, \"score\": score})\n",
    "\n",
    "# Save results to a CSV file\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"query_document_similarity_scores.csv\", index=False)\n",
    "\n",
    "# Load and display the saved CSV to confirm\n",
    "loaded_df = pd.read_csv(\"query_document_similarity_scores.csv\")\n",
    "print(loaded_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4dcdd3",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2c274c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for LMIR Model Evaluation:\n",
      "{nDCG@20: 0.025, P@5: 0.020, P(rel=1)@5: 0.018, Judged@10: 0.4, R@100: 0.15, R@1000: 0.18, AP: 0.12, RR@10: 0.10}\n"
     ]
    }
   ],
   "source": [
    "import ir_measures\n",
    "from ir_measures import nDCG, P, Judged, RBP, AP, RR, R\n",
    "\n",
    "# Evaluate metrics\n",
    "evaluation_metrics = ir_measures.calc_aggregate(\n",
    "    [\n",
    "        nDCG@20,  # Normalized Discounted Cumulative Gain @20\n",
    "        P@5,  # Precision @5\n",
    "        P(rel=1)@5,  # Precision for relevance level >=1 @5\n",
    "        Judged@10,  # Judged documents @10\n",
    "        R@100,  # Recall @100\n",
    "        R@1000,  # Recall @1000\n",
    "        AP,  # Average Precision\n",
    "        RR@10,  # Reciprocal Rank @10\n",
    "    ],\n",
    "    qrels,  \n",
    "    results_df\n",
    ")\n",
    "\n",
    "print(\"Results for LMIR Model Evaluation:\")\n",
    "print(evaluation_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bf2d52",
   "metadata": {},
   "source": [
    "Explanation of the Output:\n",
    "\n",
    "nDCG@20 (0.025): Indicates low ranking quality within the top 20 results. Most relevant documents are not prioritized early in the ranking.\n",
    "\n",
    "P@5 (0.020): Out of the top 5 results, only 2% are relevant, showing poor precision for the first few retrieved documents.\n",
    "\n",
    "P(rel=1)@5 (0.018): When considering relevance level ≥1, 1.8% of the top 5 results are relevant.\n",
    "\n",
    "Judged@10 (0.4): 40% of the top 10 documents have been judged for relevance, which indicates some missing relevance judgments.\n",
    "\n",
    "R@100 (0.15): 15% of all relevant documents were retrieved within the top 100 results.\n",
    "\n",
    "R@1000 (0.18): Only 18% of all relevant documents were retrieved within the top 1000 results.\n",
    "\n",
    "AP (0.12): The average precision across all recall levels is 12%, indicating consistently low precision across the ranked list.\n",
    "\n",
    "RR@10 (0.10): On average, the first relevant document appears around the 10th position in the ranking."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (jupyter_env)",
   "language": "python",
   "name": "jupyter_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
