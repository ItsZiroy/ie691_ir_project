{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ef496b5",
   "metadata": {},
   "source": [
    "# LMIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51169278",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ir-measures\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import ir_measures\n",
    "from ir_measures import nDCG, P, Judged\n",
    "#import nltk\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('punkt_tab') \n",
    "#import ir_datasets\n",
    "\n",
    "from funcs import load_datasets, get_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09277524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 doc_id  \\\n",
      "0  ecd810c8-4b67-4a53-a0bb-20e0214becde   \n",
      "1  bdcf1b07-7d19-41a8-923d-55d08957a8d6   \n",
      "2  b148f67a-8605-48d9-b032-f32a2280f1f0   \n",
      "3  fcd39864-6cf5-4193-8903-9a101b6863ba   \n",
      "4  2a0acf64-5fd4-43af-acbf-3f728d65ca2a   \n",
      "\n",
      "                                               title  \\\n",
      "0  Рафаэль Надаль – в четвертьфинале Открытого че...   \n",
      "1  Житель Октябрьского района, обналичив чужую ка...   \n",
      "2  Воспоминания участников войны в Афганистане из...   \n",
      "3    Глава спецслужбы ФРГ Масен отправлен в отставку   \n",
      "4  Европейские индексы - 02-04-18 | Новости Армен...   \n",
      "\n",
      "                                                text  \\\n",
      "0  Двое друзей встретились в парке, гуляя с собак...   \n",
      "1  Вы нашли ошибку\\n\\nКакой то текст который мы в...   \n",
      "2  Бежит мышка от кота, прыгает со стола и попада...   \n",
      "3  Председатель Федерального ведомства по охране ...   \n",
      "4  МОСКВА, 3 АПРЕЛЯ, АРМЕНПРЕСС. Результаты торго...   \n",
      "\n",
      "                                                 url  \\\n",
      "0  https://www.33live.ru/novosti/02-06-2019-rafae...   \n",
      "1        https://www.ugra.kp.ru/online/news/3516327/   \n",
      "2  https://www.33live.ru/novosti/21-05-2019-vospo...   \n",
      "3  https://www.dw.com/ru/%D0%B3%D0%BB%D0%B0%D0%B2...   \n",
      "4             https://armenpress.am/rus/news/928484/   \n",
      "\n",
      "                        time  \\\n",
      "0                       None   \n",
      "1  2019-06-24T08:16:36+03:00   \n",
      "2                       None   \n",
      "3                       None   \n",
      "4                       None   \n",
      "\n",
      "                                             cc_file  \n",
      "0  crawl-data/CC-NEWS/2019/06/CC-NEWS-20190602191...  \n",
      "1  crawl-data/CC-NEWS/2019/06/CC-NEWS-20190624041...  \n",
      "2  crawl-data/CC-NEWS/2019/05/CC-NEWS-20190522210...  \n",
      "3  crawl-data/CC-NEWS/2018/11/CC-NEWS-20181105143...  \n",
      "4  crawl-data/CC-NEWS/2018/04/CC-NEWS-20180403011...  \n",
      "Index(['doc_id', 'title', 'text', 'url', 'time', 'cc_file'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "datasets = load_datasets([\"ru\", \"zh\", \"fa\"])\n",
    "\n",
    "documents = pd.DataFrame(datasets[\"ru\"].docs_iter())\n",
    "\n",
    "documents.count()\n",
    "print(documents.head())\n",
    "print(documents.columns)\n",
    "queries = pd.DataFrame(datasets[\"ru\"].queries_iter())\n",
    "\n",
    "queries.head()\n",
    "\n",
    "queries.to_excel(\"translated_queries.xlsx\", index=False)\n",
    "\n",
    "# Load translated queries from the Excel file\n",
    "translated_queries = pd.read_excel(\"translated_queries.xlsx\")# Load the new dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65a161bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize and normalize\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "def preprocess(text):\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # Lowercase and remove punctuation\n",
    "    tokens = [word.lower() for word in tokens if word.isalpha()]\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)  # Join tokens back into a single string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e59809fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize and normalize Russian\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "def preprocess_ru(text):\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # Lowercase and remove punctuation\n",
    "    tokens = [word.lower() for word in tokens if word.isalpha()]\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('russian'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)  # Join tokens back into a single string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d3833a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing to the document text\n",
    "documents['processed_text'] = documents['text'].apply(preprocess_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b191396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['двое друзей встретились парке гуляя собаками предложил зайти позавтракать ближайшее кафе пустят туда собаками возразил второй первый решительно направился кафе своей немецкой овчаркой хозяин остановил словами сэр нам заходить животными слепой это хозяин извинился проводил собакой столику друг подождал улице пять минут попробовал сделать самое ваш поводырь чихуахуа скептически осведомился хозяин чихуахуа удивился мужчина подсунули анекдот', 'нашли ошибку текст который выделяем смотрим выделили слишком максимальное количество символов попробуйте снова спасибо сообщение отправлено скоро исправим', 'бежит мышка кота прыгает стола попадает бутылку недопитым вином стоящую полу барахтается говорит коту вытащи дай умереть кошмарной смертью убежишь честное слово вытащил первым делом норку шасть сидит кот обижается мышка выходи сказала убежишь мало сказать мужчине женщина нетрезвом виде анекдот', 'председатель федерального ведомства охране конституции германии масен maaßen отправлен отставку объявил министр внутренних дел фрг хорст зеехофер horst seehofer понедельник ноября зеехофер сообщил попросил отставке масена президента фрг штайнмайера глава мвд назвал свое решение неизбежным пояснив масен одном своих последних выступлений допустил неприемлемые формулировки которые делают невозможным дальнейшее сотрудничество основанное доверии принятия окончательного решения федеральным ведомством охране конституции руководить заместитель масена томас хальденванг thomas haldenwang ранее масен ходе встречи руководителей спецслужб разных стран выступил защиту своих предыдущих высказываний ставящих сомнение травлю иностранцев стороны правых экстремистов ходе беспорядков саксонском городе хемнице согласно тексту речи который получили информагентства политик затем заявил некие леворадикальные силы партии германии сдпг ранее выступавшие против создания правительственной коалиции блоком якобы посчитали высказываниями событиях хемнице хорошим поводом развала масен усомнился подлинности видео хемница масен попал шквал критики заявления недоказанной подлинности видеозаписи хемница которой видно несколько немцев гонятся темнокожими иностранцами глава ведомства частности утверждал речь идет целенаправленной дезинформации отвлечь общественность убийства хемнице гражданина фрг позже заявил оспаривает подлинность видео неправильно поняли председатели партий большой коалиции долго искали компромиссное решение судьбе масена канцлер ангела меркель angela merkel придерживалась мнения необходимости отставки поскольку вмешался текущую политику имея это права качестве руководителя спецслужбы очередь зеехофер ранее защищал масена которого отстранения должности планировалось назначить специальным советником европейским национальным вопросам мвд фрг смотрите также правительство фрг руководит германией вместе меркель меркель сдает позиции слава богу ведомство канцлера осталось наших руках горькой иронией прокомментировали итоги коалиционных переговоров некоторые политики стана ангелы меркель узнав достанется столь важное министерство финансов иначе коалицию создать считается позиции меркель ослабли уйдет раньше срока утверждает правительство фрг руководит германией вместе меркель кому достались финансы олаф шольц новый министр финансов шольца смущает продолжит дело предшественника хдс вольфганга шойбле допускать дефицита бюджета новых заимствований фоне роста экономики шольц планирует это записано коалиционном договоре хотя такая экономия нравится всем олаф шольц станет новом кабинете правительство фрг руководит германией вместе меркель сюрприз миде действующий глава мида зигмар габриэль уверен успехи посту заметят коллеги партии одобрят кандидатуру результате внутрипартийной борьбы пост достался неожиданному кандидату действующему министру юстиции хайко масу отличился принятием закона защите прав социальных сетях который критики считают началом эпохи цензуры интернете правительство фрг руководит германией вместе меркель новая родина шефа баварской хсс хорст зеехофер течение лет руководил баварией политик получит кресло министра внутренних дел переименования оно называться министерством внутренних дел строительства регионального развития неформально называют министерство родины правительство фрг руководит германией вместе меркель бундесвере остается фон дер ляйен урсула фон дер ляйен продолжит работу посту министра обороны политик партии хдс должна справиться задачей переоснащения армии реализовать обещание стран нато повысить оборонные бюджеты двух процентов ввп страны фон дер ляйен считается вероятным кандидатом пост генсека альянса выборы пройдут года правительство фрг руководит германией вместе меркель кому доверяет меркель ангела меркель считается доверяет главе ведомства канцлера петеру альтмайеру всем вопросам политика хдс ждет новая задача руководить министерством экономики энергетики отдав влиятельное финансовое ведомство хдс поставила авторитетного близкого меркель политика второй значимости экономический пост правительство фрг руководит германией вместе меркель ближе канцлеру хельге браун говорят партии хдс пользуется доверием меркель лет сих пор исполнял обязанности госминистра канцлере браун унаследует пост главы ведомства канцлера говорят начальница очень ценит браун занимая ключевую позицию сможет координировать работу внедрению новых технологий правительство фрг руководит германией вместе меркель займется правом пост министра юстиции выдвинули уроженку кельна катарину барлей юрист профессии сих пор исполняла функции министра делам семьи пожилых людей женщин молодежи правительство фрг руководит германией вместе меркель министерство труда руках генсека сдпг бывший генеральный секретарь сдпг хубертус хайль новом правительстве меркель станет министром труда политику пришел возрасте лет вступив партию году лет хайль избран бундестаг своего округа правительство фрг руководит германией вместе меркель выбор специальности юлия клёкнер родом земли важную роль играет сельское хозяйство виноделие клёкнер плечами года работы парламентским госсекретарем министерстве сельского хозяйства возглавит правительство фрг руководит германией вместе меркель вотчина баварцев министерство транспорта должен возглавить андреас шойер ранее являлся генсеком баварской партии хсс дополнительная сфера ответственности шойера внедрение цифровых технологий предыдущий министр транспорта александер добриндт баварии правительство фрг руководит германией вместе меркель мюллер продолжит свое дело пожалуй никто министров фрг считать главы мида часто колесит миру министр вопросам экономического сотрудничества развития фрг герд мюллер мюллер хсс сохранит собой пост основная задача помогать развитию бедных стран бороться причинами которые приводят миграции автор михаил бушуев андреа грунау', 'москва апреля арменпресс результаты торгов ведущих европейских фондовых биржах апреля передает арменпресс немецкий dax изменился составил пункта французский cac изменился составил пункта британский ftse изменился составил пункта российский micex изменился составил пункта rtsi вырос составил пункта']\n"
     ]
    }
   ],
   "source": [
    "# Convert the processed documents to a list\n",
    "processed_documents = documents[\"processed_text\"].tolist()\n",
    "\n",
    "# Verify a few processed documents\n",
    "print(processed_documents[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1cbf1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['british royal news impacts', 'gibraltar sovereignty brexit', 'korea trade agreement', 'north korean earthquakes nuclear testing', 'shipwrecks historical european trade']\n"
     ]
    }
   ],
   "source": [
    "# Apply preprocessing to the 'title' column\n",
    "translated_queries[\"processed_query\"] = translated_queries[\"title\"].apply(preprocess)\n",
    "\n",
    "# Convert the processed queries to a list\n",
    "processed_queries = translated_queries[\"processed_query\"].tolist()\n",
    "\n",
    "# Verify the processed queries\n",
    "print(processed_queries[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19f467c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 101: Top Documents: ['ecd810c8-4b67-4a53-a0bb-20e0214becde', 'bdcf1b07-7d19-41a8-923d-55d08957a8d6', 'b148f67a-8605-48d9-b032-f32a22801f10', 'fcd39864-6cf5-4193-8903-9a101b6863ba', '2a0acf64-5fd4-43af-acbf-3f728d65c2aa']\n",
      "Query 103: Top Documents: ['ecd810c8-4b67-4a53-a0bb-20e0214becde', 'bdcf1b07-7d19-41a8-923d-55d08957a8d6', 'b148f67a-8605-48d9-b032-f32a22801f10', 'fcd39864-6cf5-4193-8903-9a101b6863ba', '2a0acf64-5fd4-43af-acbf-3f728d65c2aa']\n",
      "Query 105: Top Documents: ['ecd810c8-4b67-4a53-a0bb-20e0214becde', 'bdcf1b07-7d19-41a8-923d-55d08957a8d6', 'b148f67a-8605-48d9-b032-f32a22801f10', 'fcd39864-6cf5-4193-8903-9a101b6863ba', '2a0acf64-5fd4-43af-acbf-3f728d65c2aa']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "# Preprocessed documents and queries are assumed to be stored in 'processed_documents' and 'processed_queries'\n",
    "vocabulary = set(word for doc in processed_documents for word in doc.split())\n",
    "\n",
    "alpha = 0.1  # Smoothing parameter, adjust as necessary\n",
    "\n",
    "def build_lm(tokens):\n",
    "    count = Counter(tokens)\n",
    "    total_tokens = sum(count.values()) or 1  # Avoid division by zero\n",
    "    # Only store non-zero probabilities\n",
    "    return {word: (count[word] + alpha) / (total_tokens + alpha * len(vocabulary)) for word in count}\n",
    "\n",
    "# Rebuild language models using the revised function\n",
    "doc_models = {idx: build_lm(doc.split()) for idx, doc in enumerate(processed_documents)}\n",
    "\n",
    "# Same for queries\n",
    "query_models = {idx: build_lm(query.split()) for idx, query in enumerate(processed_queries)}\n",
    "\n",
    "# Revised KL divergence calculation using sparse models\n",
    "def kl_divergence(lm_query, lm_document):\n",
    "    kl_div = 0\n",
    "    for word in lm_query:\n",
    "        prob_q = lm_query[word]\n",
    "        prob_d = lm_document.get(word, alpha / (alpha * len(vocabulary)))\n",
    "        kl_div += prob_q * np.log(prob_q / prob_d)\n",
    "    return kl_div\n",
    "\n",
    "# Calculate similarities with sparse models\n",
    "similarities = {q_id: {doc_id: kl_divergence(qm, dm) for doc_id, dm in doc_models.items()} for q_id, qm in query_models.items()}\n",
    "\n",
    "\n",
    "top_n = 10\n",
    "similar_documents = {\n",
    "    q_id: sorted(doc_sims.items(), key=lambda item: item[1])[:top_n] for q_id, doc_sims in similarities.items()\n",
    "}\n",
    "\n",
    "# Display results for the first three queries\n",
    "for q_id in sorted(similar_documents.keys())[:3]:\n",
    "    print(f\"Query {q_id}: Top Documents: {similar_documents[q_id]}\")\n",
    "\n",
    "# Collect results\n",
    "results = []\n",
    "for q_id, docs in similar_documents.items():\n",
    "    for doc_id, score in docs:\n",
    "        results.append({\"query_id\": q_id, \"doc_id\": doc_id, \"score\": score})\n",
    "\n",
    "# Display results for the first three queries\n",
    "for q_id in sorted(similar_documents.keys())[:3]:\n",
    "    print(f\"Query {q_id}: Top Documents: {similar_documents[q_id]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daabfd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      query_id  doc_id                                  score     \n",
      "                                                                    \n",
      "0     3         ecd810c8-4b67-4a53-a0bb-20e0214becde    1.676250  \n",
      "1     3         bdcf1b07-7d19-41a8-923d-55d08957a8d6    1.445455  \n",
      "2     3         b148f67a-8605-48d9-b032-f32a2280f1f0    1.650720  \n",
      "3     3         fcd39864-6cf5-4193-8903-9a101b6863ba    0.616157  \n",
      "4     3         2a0acf64-5fd4-43af-acbf-3f728d65ca2a    1.343578  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize a list to hold all results\n",
    "results = []\n",
    "\n",
    "# Iterate through each query and its retrieved documents\n",
    "for q_id, docs in similar_documents.items():\n",
    "    for doc_id in docs:\n",
    "        # Retrieve the similarity score for each document\n",
    "        similarity_score = similarities[q_id][doc_id]\n",
    "        # Append results including the query ID, document ID, and similarity score\n",
    "        results.append({\n",
    "            \"query_id\": q_id,\n",
    "            \"doc_id\": doc_id,\n",
    "            \"similarity_score\": similarity_score\n",
    "        })\n",
    "\n",
    "# Create a DataFrame from the results list\n",
    "results_df = pd.DataFrame(results)\n",
    "# Ensure the column is correctly named 'score'\n",
    "results_df.rename(columns={'similarity_score': 'score'}, inplace=True)\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_file_path = 'query_document_similarity_scores.csv'\n",
    "results_df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "# Load the saved CSV to confirm it's saved correctly\n",
    "loaded_df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Display the loaded DataFrame\n",
    "print(loaded_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805c54fc",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2801adc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "qrels = pd.DataFrame(datasets[\"ru\"].qrels_iter())\n",
    "#The qrels dataset contains relevance judgments that link queries to documents with relevance scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f7ecd042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the count of each relevance score in qrels\n",
    "relevance_counts = qrels[\"relevance\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "416c857e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the minimum count among relevance scores to ensure balanced sampling\n",
    "min_sample_count = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "23bca218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample equally from each relevance score\n",
    "sample_0 = qrels[qrels[\"relevance\"] == 0].sample(n=min_sample_count, random_state=42)\n",
    "sample_1 = qrels[qrels[\"relevance\"] == 1].sample(n=min_sample_count, random_state=42)\n",
    "sample_3 = qrels[qrels[\"relevance\"] == 3].sample(n=min_sample_count, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bc87ea96",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.concat([sample_0, sample_1, sample_3]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62f37f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the full HC4 RU dataset for evaluation.\n"
     ]
    }
   ],
   "source": [
    "sample = qrels\n",
    "\n",
    "# Print a confirmation message\n",
    "print(\"Using the full HC4 RU dataset for evaluation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d769eaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_ids = sample[\"doc_id\"].values\n",
    "query_ids = sample[\"query_id\"].values\n",
    "\n",
    "docs = documents[documents[\"doc_id\"].isin(doc_ids)]\n",
    "queries = queries[queries[\"query_id\"].isin(query_ids)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bb7894e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query IDs in qrels:\n",
      "{'6', '105', '250', '252', '150', '185', '157', '138', '230', '128', '249', '135', '246', '101', '137', '13', '111', '199', '253', '126', '133', '103', '234', '114', '179', '245', '146', '161', '108', '116', '134', '255', '3', '248', '231', '192', '208', '127', '107', '247', '158', '151', '233', '136', '172', '256', '229', '164', '232', '254', '14', '251', '142', '113'}\n",
      "\n",
      "Query IDs in your_run:\n",
      "{'6', '105', '250', '252', '150', '185', '157', '138', '230', '128', '249', '135', '246', '101', '137', '13', '111', '199', '253', '126', '133', '103', '234', '114', '179', '245', '146', '161', '108', '116', '134', '255', '3', '248', '231', '192', '208', '127', '107', '247', '158', '151', '233', '136', '172', '256', '229', '164', '232', '254', '14', '251', '142', '113'}\n",
      "\n",
      "Common Query IDs:\n",
      "{'6', '105', '250', '252', '150', '185', '157', '128', '230', '138', '249', '135', '137', '101', '246', '13', '111', '199', '253', '126', '133', '103', '234', '114', '179', '245', '146', '161', '108', '116', '134', '255', '3', '248', '231', '192', '208', '127', '107', '247', '158', '151', '233', '136', '172', '256', '229', '164', '232', '254', '14', '251', '142', '113'}\n",
      "\n",
      "Doc IDs in your_run:\n",
      "{'476b1f2d-71bd-4ca4-8c4c-251668490aaa', 'bdcf1b07-7d19-41a8-923d-55d08957a8d6', 'f70cc5be-3ff8-4f84-a6d4-c7515231ffbf', '36c49e77-4fef-4f48-9cf6-59bb190989bf', 'fcd39864-6cf5-4193-8903-9a101b6863ba', 'ecd810c8-4b67-4a53-a0bb-20e0214becde', '2a0acf64-5fd4-43af-acbf-3f728d65ca2a', 'd2ee3b79-8a4d-4d50-8966-a6c9d5dd41bf', 'b148f67a-8605-48d9-b032-f32a2280f1f0', 'a31bee36-e614-40de-b338-47b36911d14b', 'ebd9bd69-027a-4345-beb3-72691f2f0146'}\n",
      "\n",
      "Common Doc IDs:\n",
      "{{'9558b60f-2ec5-480a-8abb-7db03a2afc88', 'fc725c0a-8e99-4754-8cf4-fd456b0e0413', 'aa544127-7581-4103-ba6f-967b434f1899'}}\n"
     ]
    }
   ],
   "source": [
    "# Find overlapping query_ids\n",
    "common_query_ids = set(qrels[\"query_id\"]).intersection(results_df[\"query_id\"])\n",
    "\n",
    "# Filter qrels and your_run to keep only common query_ids\n",
    "qrels_filtered = qrels[qrels[\"query_id\"].isin(common_query_ids)]\n",
    "results_df_filtered = results_df[results_df[\"query_id\"].isin(common_query_ids)]\n",
    "\n",
    "# Ensure document IDs also overlap\n",
    "common_doc_ids = set(qrels_filtered[\"doc_id\"]).intersection(results_df_filtered[\"doc_id\"])\n",
    "qrels_filtered = qrels_filtered[qrels_filtered[\"doc_id\"].isin(common_doc_ids)]\n",
    "results_df_filtered = results_df_filtered[results_df_filtered[\"doc_id\"].isin(common_doc_ids)]\n",
    "\n",
    "\n",
    "# Check overlap in query_ids\n",
    "print(\"Query IDs in qrels:\\n\", set(qrels[\"query_id\"]))\n",
    "print(\"Query IDs in your_run\\n:\", set(results_df[\"query_id\"]))\n",
    "print(\"Common Query IDs:\\n\", set(qrels[\"query_id\"]).intersection(results_df[\"query_id\"]))\n",
    "\n",
    "# Check overlap in doc_ids\n",
    "#print(\"Doc IDs in qrels:\\n\", set(qrels[\"doc_id\"]))\n",
    "print(\"Doc IDs in your_run:\\n\", set(results_df[\"doc_id\"]))\n",
    "print(\"Common Doc IDs:\\n\", set(qrels[\"doc_id\"]).intersection(results_df[\"doc_id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4713695f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{nDCG@10: 0.007, P(rel=2)@5: 0.005, P@5: 0.008, Judged@10: 0.03}\n"
     ]
    }
   ],
   "source": [
    "import ir_measures\n",
    "from ir_measures import nDCG, P, Judged\n",
    "\n",
    "evaluation_metrics = ir_measures.calc_aggregate(\n",
    "    [nDCG@10, P@5, P(rel=2)@5, Judged@10],\n",
    "    qrels_filtered,\n",
    "    results_df_filtered\n",
    ")\n",
    "print(evaluation_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (jupyter_env)",
   "language": "python",
   "name": "jupyter_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
